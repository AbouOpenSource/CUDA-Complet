#include "stdio.h"
#define N 512
__global__ void dot(int *a, int *b, int *c){

	__shared__ int temp[N];
	temp[threadIdx.x] = a[threadIdx.x] * b[threadIdx.x];
	//each thread computes a pairwise product 
	// temp varible will be store in register of GPU

	// wait for each threads finished the treatmnt for its computation
	__syncthreads();

	
	//Thread 0 sums the pairwise products
	// Only the threads 0 in each block can acces to the  shared memory 
	if ( 0 == threadIdx.x) {
		int sum = 0;
		for( int i =0; i < N ; i++)
			sum +=temp[i];
		*c = sum; 
	}
}



int main( void ){

	int *a,*b,*c; // host copies of a, b and c
	int *dev_a,*dev_b, *dev_c; // device copies of a, b and c
	int size = N * sizeof(int); // we need space for an integer


	//allocate device copies of a, b , c
	cudaMalloc((void**) &dev_a, size);
	cudaMalloc((void**) &dev_b, size);
	cudaMalloc((void**) &dev_c, sizeof(int));

	a = (int*)malloc(size);
	b = (int*)malloc(size);
	c = (int*)malloc(sizeof(int));

	for (int i= 0; i<N ; i++){
		a[i]=i;
		b[i]=i*2;
		}

	//copy inputs to device (GPU)
	cudaMemcpy(dev_a, a, size , cudaMemcpyHostToDevice);
	cudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);
	
	// launch add() kernel on GPU, passing parameters
	dot<<<1  , N >>> (dev_a,dev_b,dev_c);
	
	//copy device result back to host copy of c 
	cudaMemcpy(c, dev_c, sizeof(int), cudaMemcpyDeviceToHost);

	printf("The sum is : %d", *c);

	free(a);
	free(b);
	free(c);
	
	cudaFree(dev_a);
	cudaFree(dev_b);
	cudaFree(dev_c);
		
	return 0;
}
