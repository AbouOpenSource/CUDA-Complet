#include "stdio.h"
#define THREADS_PER_BLOCK 512
#define N (2048*2048)
__global__ void dot(int *a, int *b, int *c){

	__shared__ int temp[THREADS_PER_BLOCK];
	int index = threadIdx.x + blockIdx.x * blockDim.x;
	temp[threadIdx.x] = a[index] * b[index];
	__syncthreads();

	
	//Thread 0 sums the pairwise products
	// Only the threads 0 in each block can acces to the  shared memory 
	if ( 0 == threadIdx.x) {
		int sum = 0;
		for( int i =0; i < THREADS_PER_BLOCK ; i++)
			sum +=temp[i];
		atomicAdd(c, sum);
	}
}



int main( void ){

	int *a,*b,*c; // host copies of a, b and c
	int *dev_a,*dev_b, *dev_c; // device copies of a, b and c
	int size = N * sizeof(int); // we need space for an integer


	//allocate device copies of a, b , c
	cudaMalloc((void**) &dev_a, size);
	cudaMalloc((void**) &dev_b, size);
	cudaMalloc((void**) &dev_c, sizeof(int));

	a = (int*)malloc(size);
	b = (int*)malloc(size);
	c = (int*)malloc(sizeof(int));

	for (int i= 0; i<N ; i++){
		a[i]=i;
		b[i]=i*2;
		}

	//copy inputs to device (GPU)
	cudaMemcpy(dev_a, a, size , cudaMemcpyHostToDevice);
	cudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);
	
	// launch add() kernel on GPU, passing parameters
	dot<<<N/THREADS_PER_BLOCK  , THREADS_PER_BLOCK >>> (dev_a,dev_b,dev_c);
	
	//copy device result back to host copy of c 
	cudaMemcpy(c, dev_c, sizeof(int), cudaMemcpyDeviceToHost);

	printf("The sum is : %d\n", *c);

	free(a);
	free(b);
	free(c);
	
	cudaFree(dev_a);
	cudaFree(dev_b);
	cudaFree(dev_c);
		
	return 0;
}
