////////////////////////////////////////////////////////////////////////////
//
// Copyright 1993-2015 NVIDIA Corporation.  All rights reserved.
//
// Please refer to the NVIDIA end user license agreement (EULA) associated
// with this source code for terms and conditions that govern your use of
// this software. Any use, reproduction, disclosure, or distribution of
// this software and related documentation outside the terms of the EULA
// is strictly prohibited.
//
////////////////////////////////////////////////////////////////////////////

/* Template project which demonstrates the basics on how to setup a project
* example application.
* Host code.
*/

// includes, system
#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <math.h>

// includes CUDA
#include <cuda_runtime.h>

// includes, project
#include <helper_cuda.h>
#include <helper_functions.h> // helper functions for SDK examples

////////////////////////////////////////////////////////////////////////////////
// declaration, forward
void runTest(int argc, char **argv);
typedef float DTYPE;
extern "C"
void computeGold(float *reference, float *idata, const unsigned int len);

////////////////////////////////////////////////////////////////////////////////
//! Simple test kernel for device functionality
//! @param g_idata  input data in global memory
//! @param g_odata  output data in global memory
////////////////////////////////////////////////////////////////////////////////
__global__ void
testKernel(DTYPE *out_data, unsigned int nsteps)
{
	const unsigned int tidb = threadIdx.x;
	const unsigned int tid  = blockIdx.x * blockDim.x +tidb;

	DTYPE step ;
	if(tid < nsteps ){
		step = (1.0)/((DTYPE)nsteps);
		DTYPE x = ((DTYPE) tid +0.50) * step ;
		out_data[tid] = (DTYPE) 1.0 / (1.0 + x*x);

	}
}

////////////////////////////////////////////////////////////////////////////////
// Program main
////////////////////////////////////////////////////////////////////////////////
int
main(int argc, char **argv)
{
    runTest(argc, argv);
}

////////////////////////////////////////////////////////////////////////////////
//! Run a simple test for CUDA
////////////////////////////////////////////////////////////////////////////////
void
runTest(int argc, char **argv)
{
    bool bTestResult = true;

    printf("%s Starting...\n\n", argv[0]);

    // use command-line specified CUDA device, otherwise use device with highest Gflops/s
    int devID = findCudaDevice(argc, (const char **)argv);

    StopWatchInterface *timer = 0;
    sdkCreateTimer(&timer);
    sdkStartTimer(&timer);

    unsigned int threads_per_bock = 1024;
    unsigned int nsteps = atoi(argv[1]);
    unsigned int mem_size = sizeof(float) * nbstep;
    // allocate host memory
   // float *h_idata = (float *) malloc(mem_size);

    // initalize the memory
   // for (unsigned int i = 0; i < num_threads; ++i)
   // {
     //   h_idata[i] = (float) i;
   // }

    // allocate device memory
    //float *d_idata;
    //checkCudaErrors(cudaMalloc((void **) &d_idata, mem_size));
    // copy host memory to device
    //checkCudaErrors(cudaMemcpy(d_idata, h_idata, mem_size,
		//                               cudaMemcpyHostToDevice));

    // allocate device memory for result
    //float *d_odata;
    //checkCudaErrors(cudaMalloc((void **) &d_odata, mem_size));

    // allocate host memory
    //float *h_idata = (float *) malloc(mem_size);

    // initalize the memory
    //for (unsigned int i = 0; i < num_threads; ++i)
   // {
     //   h_idata[i] = (float) i;
    //}

    // allocate device memory
    //float *d_idata;
   // checkCudaErrors(cudaMalloc((void **) &d_idata, mem_size));
    // copy host memory to device
   // checkCudaErrors(cudaMemcpy(d_idata, h_idata, mem_size,
		//                         cudaMemcpyHostToDevice));

    // allocate device memory for result
    //float *d_odata;
    //checkCudaErrors(cudaMalloc((void **) &d_odata, mem_size));


    DTYPE *d_vector;
    checkCudaErrors(cudaMalloc((void **) &d_vector,mem_size)); 
	
    // setup execution parameter
    dim3  grid((nsteps+threads_per_block-1)/threads_per_block, 1, 1);
    dim3  threads(threads_per_block, 1, 1);

    // execute the kernel
    testKernel<<< grid, threads, 0 >>>(d_vector, nbsteps);

    // check if kernel execution generated and error
    getLastCudaError("Kernel execution failed");

    // allocate mem for the result on host side
    float *h_odata = (float *) malloc(mem_size);
    // copy result from device to host
		// checkCudaErrors(cudaMemcpy(h_odata, d_odata, sizeof(float) * num_threads,
		//                         cudaMemcpyDeviceToHost));

    sdkStopTimer(&timer);
    printf("Processing time: %f (ms)\n", sdkGetTimerValue(&timer));
    sdkDeleteTimer(&timer);

    // compute reference solution
    //

    // check result
    if (checkCmdLineFlag(argc, (const char **) argv, "regression"))
    {
        // write file for regression test
   //     sdkWriteFile("./data/regression.dat", h_odata, num_threads, 0.0f, false);
    }
    else
    {
        // custom output handling when no regression test running
        // in this case check if the result is equivalent to the expected solution
    //    bTestResult = compareData(reference, h_odata, num_threads, 0.0f, 0.0f);
    }

    // cleanup memory
   // free(h_idata);
  // free(h_odata);
 //   free(reference);
 //   checkCudaErrors(cudaFree(d_idata));
//    checkCudaErrors(cudaFree(d_odata));

    extResult ? EXIT_SUCCESS : EXIT_FAILURE);
}
